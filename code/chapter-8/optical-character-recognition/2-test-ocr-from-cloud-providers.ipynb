{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud APIs for Computer Vision: Up and Running in 15 Minutes\n",
    "\n",
    "This code is part of [Chapter 8- Cloud APIs for Computer Vision: Up and Running in 15 Minutes ](https://learning.oreilly.com/library/view/practical-deep-learning/9781492034858/ch08.html).\n",
    "\n",
    "## Test OCR from Cloud Providers\n",
    "\n",
    "This code sample details how one image and a directory of images can be uploaded to various cloud providers using the [`script.py`](https://github.com/PracticalDL/Practical-Deep-Learning-Book/blob/master/code/chapter-8/experiment-scripts/script.py). We will be using this script for both the OCR and image tagging experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coco_text\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import script\n",
    "from script import process_images\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='train2014'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare how various cloud providers fare, let's view and compare just one image and the results from the cloud providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"000000229378.jpg\"\n",
    "I = io.imread('../%s/%s'%(dataDir,filename))\n",
    "plt.figure()\n",
    "plt.imshow(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text in the image is pretty small and even with a normal human eyesight, its pretty difficult to decipher all the words. We had to enlarge the image to really see all the words.\n",
    "\n",
    "Now, let's upload this image to the cloud providers and see how well they do. We will be using the Google, Microsoft, Amazon, IBM Watson and Clarifai cloud providers so make sure you register and generate an API key for each and replace it in the [`script.py`](https://github.com/PracticalDL/Practical-Deep-Learning-Book/blob/master/code/chapter-8/experiment-scripts/script.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./experiment-scripts/script.py -d <PATH_TO_TRAIN2014>/000000229378.jpg -s google -t ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./experiment-scripts/script.py -d <PATH_TO_TRAIN2014>/000000229378.jpg -s microsoft -t ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./experiment-scripts/script.py -d <PATH_TO_TRAIN2014>/000000229378.jpg -s amazon -t ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBM Watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./experiment-scripts/script.py -d <PATH_TO_TRAIN2014>/000000229378.jpg -s watson -t ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clarifai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./experiment-scripts/script.py -d <PATH_TO_TRAIN2014>/000000229378.jpg -s clarifai -t ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! Different cloud providers are able to pick up different words in the image. But what about running against all images, after all that is how we will be able to generate useful benchmark. Let's look at that next."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
